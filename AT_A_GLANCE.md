# ğŸ¯ YOUR PROJECT AT A GLANCE

**Project:** Automated Question Paper Generation System  
**Date:** January 27, 2026  
**Status:** âœ… READY FOR VIVA

---

## ğŸ“Š THE ESSENCE IN ONE PAGE

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         WHAT YOU'VE BEEN GIVEN (Models & Tools)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Pre-trained Models:                                        â”‚
â”‚  âœ… SBERT (all-MiniLM-L6-v2) - 22 MB                        â”‚
â”‚  âœ… Tesseract OCR - Google's model                          â”‚
â”‚                                                              â”‚
â”‚  Frameworks:                                                â”‚
â”‚  âœ… PyTorch - Computation engine                            â”‚
â”‚  âœ… Scikit-learn - ML utilities                             â”‚
â”‚  âœ… FastAPI - Web framework                                 â”‚
â”‚  âœ… React - Frontend framework                              â”‚
â”‚                                                              â”‚
â”‚  Libraries:                                                 â”‚
â”‚  âœ… PyMuPDF - PDF extraction                                â”‚
â”‚  âœ… NLTK - NLP utilities                                    â”‚
â”‚  âœ… HuggingFace - Model hub                                 â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         WHAT YOU BUILT (Your Contribution)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  âœ… System Architecture                                     â”‚
â”‚  âœ… Semantic Matching Pipeline                              â”‚
â”‚  âœ… Question Generation Engine                              â”‚
â”‚  âœ… Exam Pattern Configuration                              â”‚
â”‚  âœ… End-to-End Integration                                  â”‚
â”‚  âœ… User Interface (Frontend)                               â”‚
â”‚  âœ… API Backend (FastAPI)                                   â”‚
â”‚  âœ… Data Processing Logic                                   â”‚
â”‚  âœ… Error Handling & Validation                             â”‚
â”‚  âœ… Production Optimization                                 â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              KEY METRICS (Remember These!)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Speed:                Performance:                         â”‚
â”‚  â€¢ 5 sec/100 Q        â€¢ 81.9% (SBERT)                     â”‚
â”‚  â€¢ 50ms/question      â€¢ 85-95% (OCR)                      â”‚
â”‚                                                              â”‚
â”‚  System:              Scalability:                          â”‚
â”‚  â€¢ No GPU             â€¢ 1000+ chunks âœ“                     â”‚
â”‚  â€¢ 22 MB model        â€¢ 10-50 users âœ“                      â”‚
â”‚  â€¢ Offline capable âœ“  â€¢ Production ready âœ“                 â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        THE QUESTION EXAMINERS WILL ASK                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â“ "Did you train any models?"                            â”‚
â”‚  âœ“ "No - used pre-trained for pragmatic reasons"           â”‚
â”‚                                                              â”‚
â”‚  â“ "Why SBERT and not GPT?"                               â”‚
â”‚  âœ“ "SBERT is faster, offline, more predictable"           â”‚
â”‚                                                              â”‚
â”‚  â“ "Is this really AI?"                                   â”‚
â”‚  âœ“ "Yes - hybrid AI + rules for control"                   â”‚
â”‚                                                              â”‚
â”‚  â“ "How is this different from alternatives?"             â”‚
â”‚  âœ“ "Complete system: semantic + templates + UI"           â”‚
â”‚                                                              â”‚
â”‚  â“ "What are limitations?"                                â”‚
â”‚  âœ“ "Template diversity, no multi-language, etc."          â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ YOUR TALKING POINTS (Memorize!)

### **30 Second Version:**
"I built an automated question paper generation system using semantic embeddings. It uses two pre-trained models: SBERT for understanding topic-content relationships and Tesseract OCR for document processing. The system combines AI-powered semantic matching with custom business logic based on Bloom's taxonomy. It works completely offline, generates 100-question papers in 5 seconds, and requires no GPU."

### **2 Minute Version:**
"My system automates question paper generation for educational institutions. It uses a pragmatic hybrid approach combining pre-trained models with domain-specific logic.

First, users upload a syllabus PDF. The system extracts topics using Tesseract OCR for scanned documents or PyMuPDF for native PDFs.

Next, they upload a textbook PDF, which I chunk into manageable segments.

The key innovation is semantic mapping: I use SBERT, a pre-trained neural network, to convert both topics and chunks into 384-dimensional semantic vectors. Cosine similarity then finds the best-matching chunks for each topic.

For question generation, I created Bloom's taxonomy templates. The system selects questions matching the specified cognitive level, marks, and module, then fills templates with relevant content from the chunks.

This produces diverse, relevant questions aligned with educational standards. No GPU needed, works offline, generates papers in seconds. I chose pre-trained models instead of training from scratch because it's faster, more reliable, and follows industry best practices."

---

## ğŸ“š YOUR DOCUMENTATION TOOLKIT

```
START HERE
    â†“
Quick Reference Card (15 min)
    â†“
â”œâ”€â†’ Going to viva NOW? â†’ Stop here & go!
â”œâ”€â†’ Have 1 hour? â†’ Read Final Summary
â”œâ”€â†’ Have 4 hours? â†’ Read Complete Guide + Diagrams
â””â”€â†’ Have full day? â†’ Do everything + ChatGPT prompts
    â†“
READY FOR VIVA âœ“
```

---

## âœ… PRE-VIVA CONFIDENCE CHECK

**Can you answer these?**

1. "What are the two pre-trained models you used?"
   - SBERT and Tesseract âœ“

2. "Why didn't you train models yourself?"
   - Would need millions of samples and weeks of GPU time âœ“

3. "How does semantic matching work?"
   - SBERT encodes to vectors â†’ cosine similarity â†’ top-K selection âœ“

4. "Is this production-ready?"
   - Yes. Works offline, fast, no GPU, handles real PDFs âœ“

5. "What makes your project special?"
   - System integration: complete pipeline from PDF to paper âœ“

**If you can answer these, you're ready!**

---

## ğŸš€ FINAL GAME PLAN

```
ğŸ“… 1 WEEK BEFORE:
   â€¢ Read all documents (3-4 hours)
   â€¢ Use ChatGPT prompts (2-3 hours)
   â€¢ Make flashcards (1 hour)

ğŸ“… 2 DAYS BEFORE:
   â€¢ Review Quick Reference Card
   â€¢ Practice 2-minute explanation
   â€¢ Mock viva with friend

ğŸ“… DAY BEFORE:
   â€¢ Light review (30 minutes)
   â€¢ Get good sleep (8+ hours!)

ğŸ“… MORNING OF:
   â€¢ Quick Reference Card review (5 min)
   â€¢ Breathing exercises (3 min)
   â€¢ Arrive early (20 min before)

ğŸ“… DURING VIVA:
   â€¢ Answer confidently
   â€¢ Admit if you don't know
   â€¢ Show your thinking
   â€¢ Reference your code if asked
```

---

## ğŸ¯ VIVA GOLD TIPS

**DO:**
âœ… Explain clearly and concisely
âœ… Use examples from your code
âœ… Show understanding of trade-offs
âœ… Admit limitations honestly
âœ… Discuss future improvements
âœ… Ask for clarification if unsure
âœ… Take 3 seconds to think before answering

**DON'T:**
âŒ Make up technical details
âŒ Claim credit for pre-trained models
âŒ Pretend to understand something you don't
âŒ Go off on tangents
âŒ Answer too quickly (shows lack of thought)
âŒ Be defensive about your choices
âŒ Say "I don't know" without trying first

---

## ğŸ“ˆ WHY YOUR PROJECT IS STRONG

1. **Pragmatic approach**
   - Right tool for right job
   - Industry best practice

2. **Complete solution**
   - End-to-end implementation
   - Frontend + Backend + ML integration

3. **Production-ready**
   - Works without GPU
   - Offline capable
   - Tested with real data

4. **Well-thought-out**
   - Clear architecture
   - Documented decisions
   - Honest about limitations

5. **Educational value**
   - Addresses real problem
   - Practical for institutions
   - Scalable approach

---

## ğŸ’¬ IF YOU GET NERVOUS

**Remember:**
- You know your system better than anyone
- Your approach is professional and justified
- You've thought about alternatives
- Examiners want you to succeed
- It's okay to say "I don't know"
- Taking time to think is good
- Your project is solid work

---

## ğŸ‰ YOU'VE GOT THIS!

**What You Have:**
âœ… Complete understanding of all models
âœ… Clear explanations for questions
âœ… Answers to likely follow-ups
âœ… Visual aids for complex concepts
âœ… Professional documentation
âœ… ChatGPT prompts for deeper learning
âœ… Quick reference materials
âœ… Confidence that you're prepared

**You're Ready! ğŸš€**

---

## ğŸ“– ONE LAST THING

**The Most Important Insight:**

Your project isn't just about using SBERT and Tesseract. Your real contribution is:

**Building a complete system that**
- **Understands meaning** (semantic matching)
- **Handles diversity** (native + scanned PDFs)
- **Enforces standards** (Bloom's taxonomy)
- **Scales efficiently** (no GPU needed)
- **Works reliably** (offline, no APIs)
- **Solves real problems** (educators' pain point)

This is exactly what industry needs and what examiners want to see.

**Go crush that viva! ğŸ“**

---

## ğŸ“ EMERGENCY ANSWERS

**If completely stuck:**

Q: "Explain your models"
A: "I used Sentence-Transformers for semantic understanding and Tesseract for document processing. Both pre-trained. This hybrid approach gives me AI intelligence with rule-based control."

Q: "Why should I believe this works?"
A: "I can show you the demo. Here's performance data. These are proven production models."

Q: "What's the hardest part?"
A: "Ensuring semantic relevance. I validate with similarity scores, manual checks, and output validation."

Q: "Future work?"
A: "Better question diversity, multi-language support, automated answer keys, LLM integration."

---

**Final Confidence Boost:**

You've read/will read ~81 pages of documentation about your system.
Your examiners will know it for ~30 minutes.
You win. ğŸ˜Š

**Go show them what you've built!**

